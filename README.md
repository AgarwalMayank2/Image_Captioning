# Image Captioning

This project implements an Image Captioning system that generates natural language descriptions for input images. The model is trained on a curated image-caption dataset and aims to bridge the gap between computer vision and natural language processing. This architecture combines strong image understanding with the generative capabilities of transformers, producing impressive results even on unseen images.

# Model Architecture
`pre_processing.py`: Building the vocab from the data.
